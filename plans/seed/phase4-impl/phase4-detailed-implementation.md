# Phase 4: Video Worker - Detailed Implementation Plan

**Date**: 2025-11-01
**Base**: Phase 2 (Database) âœ… Completed
**Dependencies**: Phase 3 (Backend API), Phase 5 (Storage - MinIO/RabbitMQ)
**Estimated Time**: 4-5 days

## Current Status

**Existing Structure**:

```
apps/worker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts           âœ… Placeholder (DB connection only)
â”‚   â”œâ”€â”€ transcoder.ts      âœ… Placeholder (interface only)
â”‚   â”œâ”€â”€ consumer.ts        âœ… Empty
â”‚   â”œâ”€â”€ live-stream.ts     âœ… Empty
â”‚   â”œâ”€â”€ types.ts           âœ… Empty
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ storage.ts     âœ… Empty
â”œâ”€â”€ package.json           âœ… Dependencies configured
â””â”€â”€ tsconfig.json          âœ… Configured
```

**Dependencies Already Installed**:

- âœ… `amqplib` (RabbitMQ)
- âœ… `fluent-ffmpeg` (FFmpeg wrapper)
- âœ… `minio` (S3-compatible storage)
- âœ… `@repo/database` (Prisma client)

## Implementation Breakdown

### PHASE 01: Storage Service (Day 1)

**File**: `apps/worker/src/services/storage.ts`

**Tasks**:

1. Implement MinIO client initialization
2. Create methods:
   - `downloadFile(key, localPath)` - Download from MinIO
   - `uploadFile(localPath, key)` - Upload to MinIO
   - `uploadDirectory(localDir, prefix)` - Batch upload
   - `fileExists(key)` - Check file existence
   - `deleteFiles(prefix)` - Cleanup

**Dependencies**:

- MinIO running (docker-compose.dev.yml)
- Environment: `MINIO_ENDPOINT`, `MINIO_ACCESS_KEY`, `MINIO_SECRET_KEY`

**Verification**:

```bash
# Test download/upload
bun run dev  # Should connect to MinIO
```

**Success Criteria**:

- âœ… MinIO client connects
- âœ… Can download test file
- âœ… Can upload test file
- âœ… File operations don't throw errors

---

### PHASE 02: FFmpeg Transcoder - VOD (Day 2)

**File**: `apps/worker/src/transcoder.ts`

**Tasks**:

1. Install FFmpeg locally

   ```bash
   # macOS
   brew install ffmpeg

   # Verify
   ffmpeg -version
   ```

2. Implement functions:
   - `getVideoMetadata(inputPath)` - Extract duration, resolution
   - `generateThumbnail(inputPath, outputPath)` - Create thumbnail at 1s
   - `transcodeToHLS(options)` - Main transcoding logic
   - `generateMasterPlaylist(outputDir)` - Create master.m3u8

3. HLS Variants Configuration:

   ```typescript
   const HLS_VARIANTS = [
     { resolution: '1080p', width: 1920, height: 1080, bitrate: 5000 },
     { resolution: '720p', width: 1280, height: 720, bitrate: 2800 },
     { resolution: '480p', width: 854, height: 480, bitrate: 1400 }
   ]
   ```

4. FFmpeg Command Template:
   ```bash
   ffmpeg -i input.mp4 \
     -c:v libx264 -preset medium -crf 23 \
     -b:v 5000k -maxrate 6000k -bufsize 10000k \
     -vf scale=1920:1080 \
     -c:a aac -b:a 128k \
     -hls_time 6 -hls_playlist_type vod \
     -hls_segment_filename "1080p/segment_%03d.ts" \
     1080p/playlist.m3u8
   ```

**Environment Variables**:

```env
WORKER_TEMP_DIR=/tmp/transcode
FFMPEG_PRESET=medium
FFMPEG_CRF=23
```

**Verification**:

```bash
# Create test video
ffmpeg -f lavfi -i testsrc=duration=10:size=1920x1080:rate=30 \
  -pix_fmt yuv420p test.mp4

# Test transcoding
bun run test-transcode
```

**Success Criteria**:

- âœ… Can extract metadata
- âœ… Generates thumbnail (720p, JPG)
- âœ… Creates 3 HLS variants
- âœ… Generates master.m3u8
- âœ… Output files valid (playable)

---

### PHASE 03: RabbitMQ Consumer (Day 3)

**File**: `apps/worker/src/consumer.ts`

**Tasks**:

1. Implement RabbitMQ connection

   ```typescript
   async function connectRabbitMQ() {
     const conn = await amqp.connect(process.env.RABBITMQ_URL!)
     const channel = await conn.createChannel()
     await channel.assertQueue('video-transcode', { durable: true })
     return { conn, channel }
   }
   ```

2. Implement consumer:
   - Listen to 'video-transcode' queue
   - Parse job: `{ videoId, inputKey }`
   - Process with `processTranscodeJob()`
   - Ack on success / Nack on failure

3. Implement `processTranscodeJob()`:

   ```typescript
   async function processTranscodeJob(job: TranscodeJob) {
     // 1. Update video status to PROCESSING
     // 2. Download from MinIO
     // 3. Transcode with FFmpeg
     // 4. Upload outputs to MinIO
     // 5. Create VideoVariant records
     // 6. Update video status to READY
     // 7. Cleanup temp files
   }
   ```

4. Error Handling:
   - FFmpeg fails â†’ status: FAILED
   - Upload fails â†’ retry 3x â†’ FAILED
   - Database fails â†’ log error, Nack

**Dependencies**:

- RabbitMQ running (docker-compose.dev.yml)
- Environment: `RABBITMQ_URL`

**Verification**:

```bash
# Start worker
bun run dev

# Check RabbitMQ management
open http://localhost:15672
# Login: admin/password
# Queue should show consumer connected
```

**Success Criteria**:

- âœ… Connects to RabbitMQ
- âœ… Queue 'video-transcode' exists
- âœ… Consumer processes jobs
- âœ… Updates database correctly
- âœ… Handles errors gracefully

---

### PHASE 04: Integration & End-to-End (Day 3-4)

**File**: `apps/worker/src/index.ts`

**Tasks**:

1. Update main entry:

   ```typescript
   import { startWorker } from './consumer'
   import { prisma } from '@repo/database'

   async function main() {
     console.log('ðŸŽ¬ Video processing worker starting...')

     await prisma.$connect()
     console.log('âœ… Database connected')

     await startWorker()
     console.log('âœ… Worker listening for jobs')
   }
   ```

2. Add graceful shutdown:
   - SIGINT handler â†’ close RabbitMQ, disconnect DB
   - SIGTERM handler â†’ same
   - Process cleanup

3. Integration Testing:
   - Upload test video via API
   - Worker processes job
   - Verify outputs in MinIO
   - Verify database updated

**Test Flow**:

```bash
# Terminal 1: Start services
docker-compose -f docker-compose.dev.yml up

# Terminal 2: Start worker
cd apps/worker
bun run dev

# Terminal 3: Upload test video
curl -X POST http://localhost:3001/api/upload/presign \
  -H "Content-Type: application/json" \
  -d '{"fileName": "test.mp4", "fileSize": 1000000, "contentType": "video/mp4"}'

# Upload file to presigned URL
curl -X PUT [PRESIGNED_URL] --upload-file test.mp4

# Complete upload
curl -X POST http://localhost:3001/api/upload/[videoId]/complete

# Check worker logs - should process
# Check MinIO - should have outputs
# Check DB - should be READY
```

**Success Criteria**:

- âœ… Worker starts without errors
- âœ… Processes real jobs end-to-end
- âœ… Outputs appear in MinIO
- âœ… Database reflects correct status
- âœ… No memory leaks

---

### PHASE 05: Live Streaming (Day 4-5)

**File**: `apps/worker/src/live-stream.ts`

**Tasks**:

1. Implement WebRTC â†’ HLS conversion
   - Accept WebRTC stream
   - Pipe to FFmpeg
   - Output HLS segments (2s each)

2. Implement `startLiveStream()`:

   ```typescript
   async function startLiveStream(videoId: string, streamKey: string) {
     const outputDir = `/tmp/live-${videoId}`

     // FFmpeg for live HLS
     const ffmpeg = spawn('ffmpeg', [
       '-i',
       `rtmp://localhost/live/${streamKey}`,
       '-c:v',
       'libx264',
       '-preset',
       'veryfast',
       '-tune',
       'zerolatency',
       '-c:a',
       'aac',
       '-f',
       'hls',
       '-hls_time',
       '2',
       '-hls_list_size',
       '10',
       '-hls_flags',
       'delete_segments+append_list',
       `${outputDir}/index.m3u8`
     ])

     // Watch directory â†’ upload segments to MinIO
   }
   ```

3. Implement file watcher:
   - Monitor output directory
   - Upload .ts and .m3u8 files to MinIO
   - Real-time sync for low latency

4. Implement `stopLiveStream()`:
   - Kill FFmpeg process
   - Cleanup temp directory
   - Optionally save recording

**File**: `apps/worker/src/hls-packager.ts`

**Tasks**:

- Real-time segment upload
- Manifest updates
- Cleanup old segments

**Verification**:

```bash
# Test RTMP ingest
ffmpeg -re -i test.mp4 -c copy -f flv rtmp://localhost/live/[streamKey]

# Check MinIO for segments
# Check HLS playback
```

**Success Criteria**:

- âœ… Accepts RTMP stream
- âœ… Converts to HLS in real-time
- âœ… Uploads segments to MinIO
- âœ… Latency < 10 seconds
- âœ… Can stop stream cleanly

---

### PHASE 06: Performance & Optimization (Day 5)

**Tasks**:

1. Memory Management:
   - Cleanup temp files after each job
   - Monitor memory usage
   - Set FFmpeg buffer limits

2. Concurrent Jobs:
   - Set RabbitMQ prefetch: 1
   - Handle multiple workers (scaling)

3. Progress Tracking:
   - FFmpeg progress events
   - Update database with %
   - WebSocket notifications (optional)

4. Error Recovery:
   - Retry failed uploads
   - Handle disk space errors
   - Graceful FFmpeg crashes

**Environment Tuning**:

```env
WORKER_CONCURRENCY=1        # Jobs per worker
WORKER_TEMP_DIR=/tmp/transcode
FFMPEG_PRESET=medium        # veryfast/faster/fast/medium/slow
FFMPEG_CRF=23               # Quality (18-28)
MAX_CONCURRENT_TRANSCODES=2
```

**Success Criteria**:

- âœ… Memory < 2GB per job
- âœ… Disk cleanup automatic
- âœ… No zombie FFmpeg processes
- âœ… Handles failures gracefully

---

## File Checklist

### To Implement:

- [ ] `src/services/storage.ts` - MinIO operations
- [ ] `src/transcoder.ts` - FFmpeg VOD transcoding
- [ ] `src/consumer.ts` - RabbitMQ job processing
- [ ] `src/index.ts` - Main worker entry (update)
- [ ] `src/live-stream.ts` - Live streaming handler
- [ ] `src/hls-packager.ts` - Real-time HLS packaging
- [ ] `src/types.ts` - Job interfaces

### To Update:

- [ ] `.env` - Add worker env vars
- [ ] `docker-compose.dev.yml` - Ensure services running

---

## Testing Strategy

### Unit Tests:

```typescript
// test/transcoder.test.ts
describe('Transcoder', () => {
  it('generates thumbnail', async () => {
    const result = await generateThumbnail('test.mp4', 'thumb.jpg')
    expect(fs.existsSync('thumb.jpg')).toBe(true)
  })

  it('transcodes to HLS', async () => {
    await transcodeToHLS({ inputPath: 'test.mp4', outputDir: '/tmp/out', videoId: '123' })
    expect(fs.existsSync('/tmp/out/master.m3u8')).toBe(true)
  })
})
```

### Integration Tests:

1. Upload test video
2. Worker processes
3. Verify outputs in MinIO
4. Verify database records
5. Test playback in browser

### Load Tests:

- Queue 10 jobs simultaneously
- Monitor memory/CPU
- Verify all complete successfully

---

## Environment Variables

**Add to `.env`**:

```env
# Worker
WORKER_CONCURRENCY=1
WORKER_TEMP_DIR=/tmp/transcode
FFMPEG_PRESET=medium
FFMPEG_CRF=23
MAX_CONCURRENT_TRANSCODES=1

# RabbitMQ (existing)
RABBITMQ_URL=amqp://admin:password@localhost:5672

# MinIO (existing)
MINIO_ENDPOINT=localhost
MINIO_PORT=9000
MINIO_USE_SSL=false
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=password

# Database (existing)
DATABASE_URL=postgresql://postgres:password@localhost:5445/streaming_video
```

---

## Success Criteria (Overall)

### VOD Transcoding:

- âœ… Worker connects to RabbitMQ
- âœ… Processes transcode jobs
- âœ… Creates 3 HLS variants (480p, 720p, 1080p)
- âœ… Generates thumbnail
- âœ… Uploads to MinIO
- âœ… Updates database (VideoVariant records)
- âœ… Status: PENDING â†’ PROCESSING â†’ READY

### Live Streaming:

- âœ… Accepts RTMP/WebRTC stream
- âœ… Converts to HLS real-time
- âœ… Low latency (< 10s)
- âœ… Uploads segments continuously
- âœ… Can stop stream gracefully

### Performance:

- âœ… Transcode speed: 0.5-1x realtime
- âœ… Memory: < 2GB per job
- âœ… Temp files cleaned up
- âœ… No memory leaks

### Error Handling:

- âœ… FFmpeg errors â†’ status FAILED
- âœ… Upload errors â†’ retry â†’ FAILED
- âœ… Queue errors handled
- âœ… Graceful shutdown

---

## Dependencies Checklist

### Services (docker-compose.dev.yml):

- [ ] PostgreSQL (port 5445)
- [ ] RabbitMQ (ports 5672, 15672)
- [ ] MinIO (ports 9000, 9001)
- [ ] Redis (port 6379) - optional for Phase 3

### Local Tools:

- [ ] FFmpeg installed (`ffmpeg -version`)
- [ ] Node.js >= 22
- [ ] Bun package manager

### Phase Dependencies:

- [ ] Phase 2 âœ… (Database schema)
- [ ] Phase 3 (Backend API - upload endpoints)
- [ ] Phase 5 (Storage - MinIO setup)

---

## Unresolved Questions

1. **Video Formats**: Support only MP4 or also AVI, MOV, MKV?
2. **Max File Size**: Limit upload size? (e.g., 2GB)
3. **Retention Policy**: How long keep temp files? Auto-delete after 24h?
4. **Concurrent Workers**: Deploy multiple workers for scaling?
5. **Progress Updates**: Real-time progress via WebSocket or polling?
6. **Live Recording**: Save live streams as VOD after completion?
7. **Audio-Only**: Support audio-only transcoding (podcast use case)?
8. **Subtitles**: Support VTT/SRT subtitle files in HLS?
9. **DRM**: Content protection needed for VOD?
10. **CDN**: Plan for CDN integration (Cloudflare, etc.)?

---

## Next Steps After Phase 4

**Phase 5**: Frontend - Video player, upload UI, live streaming UI
**Phase 6**: Deployment - Docker production builds, CI/CD
**Phase 7**: Testing & Polish - E2E tests, error handling, optimization
